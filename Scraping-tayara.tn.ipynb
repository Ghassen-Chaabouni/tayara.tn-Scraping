{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []   # Were we will store the location\n",
    "price = []      # Were we will store the price\n",
    "category = []   # Were we will store the category (terrain, villa,...)\n",
    "chambres = []   # Were we will store the number of rooms\n",
    "salles_de_bains = []   # Were we will store the number of bathrooms\n",
    "superficie = []    # Were we will store the area\n",
    "date = []          # Were we will store the date of the ad\n",
    "type_de_transaction = []  # Were we will store the transaction type (A louer, A vendre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\webdrivers\\chromedriver.exe\")  # Change with chromedrive.exe path\n",
    "driver.get('https://www.tayara.tn/l/tunis/c/immobilier')      # Change with any tayara.tn URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_button = driver.find_elements_by_xpath('/html/body/div[1]/div/div[2]/div[2]/div[3]/div[2]/button')[0]  # Find the show more button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):   # We will click the show more button 10 times\n",
    "    submit_button.click()     # Click the button\n",
    "    time.sleep(3)             # Wait till the page load\n",
    "\n",
    "page = soup(driver.page_source, 'html.parser')    # \"page\" contains the html code \n",
    "house_containers = page.find_all(\"div\", class_=\"card\")   # Find where the ad is located in the htm code. In this case it's in <div class=\"card\">...</div>\n",
    "print(len(house_containers))     # len(house_containers) is the number of ads we loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in house_containers:\n",
    "    find_link = data.find_all(\"a\", class_=\"delta-link delta-link__primary\")    # get the link of the ad. It's stored in <a class=\"delta-link delta-link__primary\">...</a>\n",
    "    L = str(find_link[0]).split(\" \")          \n",
    "    link = \"https://tayara.tn\"+L[3][6:-6]\n",
    "\n",
    "    response2 = requests.get(link)      # Open the ad link\n",
    "    page2 = soup(response2.text, 'html.parser')   # page2 contains the html code of the ad page \n",
    "\n",
    "    # Get the price\n",
    "    try:\n",
    "        house_containers2 = page2.find_all(\"div\", class_=\"_3VhHF _1q9YR _3PJSU\")[0]\n",
    "        find_price = str(house_containers2.find_all(\"span\")).split(\" \")\n",
    "        price_value = find_price[2].split(\">\")\n",
    "        price_value = price_value[0][12:-1]\n",
    "        price.append(price_value)\n",
    "        print(price_value)\n",
    "    except:  # In case if the ad donsen't containt a price we will add a NULL value\n",
    "        price.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "    \n",
    "    # Get the location\n",
    "    try:\n",
    "        find_location = str(house_containers2.find_all(\"p\", class_=\"_15IPb\")[1])[46:-4]\n",
    "        location.append(find_location)\n",
    "        print(find_location)\n",
    "    except:\n",
    "        location.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "\n",
    "    # Get the category\n",
    "    try:\n",
    "        find_category = str(house_containers2.find_all(\"p\", class_=\"_15IPb\")[2])[46:-4]\n",
    "        category.append(find_category)\n",
    "        print(find_category)\n",
    "    except:\n",
    "        category.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "\n",
    "    # Get the date\n",
    "    try:\n",
    "        find_date = str(house_containers2.find_all(\"p\", class_=\"_15IPb\")[0])[45:-11]\n",
    "        date.append(find_date)\n",
    "        print(find_date)\n",
    "    except:\n",
    "        date.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "\n",
    "    # Get the transaction type\n",
    "    try:\n",
    "        house_containers3 = page2.find_all(\"div\", class_=\"DbXTC b7ygi\")[3]\n",
    "        find_type_de_transaction = str(house_containers3.find_all(\"p\", class_=\"_15IPb\")[1])[18:-4]\n",
    "        type_de_transaction.append(find_type_de_transaction)\n",
    "        print(find_type_de_transaction)\n",
    "    except:\n",
    "        type_de_transaction.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "\n",
    "    # Get the number of rooms\n",
    "    try:\n",
    "        find_chambres = str(house_containers3.find_all(\"p\", class_=\"_15IPb\")[3])[18:-4]\n",
    "        chambres.append(find_chambres)\n",
    "        print(find_chambres)\n",
    "    except:\n",
    "        chambres.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "    \n",
    "    # Get the number of bathrooms\n",
    "    try:\n",
    "        find_salles_de_bains = str(house_containers3.find_all(\"p\", class_=\"_15IPb\")[5])[18:-4]\n",
    "        salles_de_bains.append(find_salles_de_bains)\n",
    "        print(find_salles_de_bains)\n",
    "    except:\n",
    "        salles_de_bains.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "\n",
    "    # Get the area\n",
    "    try:\n",
    "        find_superficie = str(house_containers3.find_all(\"p\", class_=\"_15IPb\")[7])[18:-4]\n",
    "        superficie.append(find_superficie)\n",
    "        print(find_superficie)\n",
    "    except:\n",
    "        superficie.append(\"NULL\")\n",
    "        print(\"NULL\")\n",
    "\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3564, 9)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"location\"] = location  \n",
    "df[\"category\"] = category\n",
    "df[\"chambres\"] = chambres\n",
    "df[\"salles_de_bains\"] = salles_de_bains\n",
    "df[\"superficie\"] = superficie\n",
    "df[\"type_de_transaction\"] = type_de_transaction\n",
    "df[\"date\"] = date\n",
    "df[\"price\"] = price\n",
    "\n",
    "d = df.to_csv(\"./tunis.csv\")     # store the data in csv file\n",
    "d1 = pd.read_csv(\"./tunis.csv\")\n",
    "print(d1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After collecting all the data from all the cities, we will store them in one csv file\n",
    "\n",
    "x1 = pd.read_csv(\"./ariana.csv\")\n",
    "x2 = pd.read_csv(\"./beja.csv\")\n",
    "x3 = pd.read_csv(\"./ben-arous.csv\")\n",
    "x4 = pd.read_csv(\"./bizerte.csv\")\n",
    "x5 = pd.read_csv(\"./gabes.csv\")\n",
    "x6 = pd.read_csv(\"./gafsa.csv\")\n",
    "x7 = pd.read_csv(\"./jendouba.csv\")\n",
    "x8 = pd.read_csv(\"./kairouan.csv\")\n",
    "x9 = pd.read_csv(\"./kasserine.csv\")\n",
    "x10 = pd.read_csv(\"./kebeli.csv\")\n",
    "x11 = pd.read_csv(\"./la-manouba.csv\")\n",
    "x12 = pd.read_csv(\"./le-kef.csv\")\n",
    "x13 = pd.read_csv(\"./mahdia.csv\")\n",
    "x14 = pd.read_csv(\"./medenine.csv\")\n",
    "x15 = pd.read_csv(\"./monastir.csv\")\n",
    "x16 = pd.read_csv(\"./sidi-bouzid.csv\")\n",
    "x17 = pd.read_csv(\"./siliana.csv\")\n",
    "x18 = pd.read_csv(\"./sousse.csv\")\n",
    "x19 = pd.read_csv(\"./tataouine.csv\")\n",
    "x20 = pd.read_csv(\"./tozeur.csv\")\n",
    "x21 = pd.read_csv(\"./zaghouan.csv\")\n",
    "x22 = pd.read_csv(\"./sfax.csv\")\n",
    "x23 = pd.read_csv(\"./nabeul.csv\")\n",
    "x24 = pd.read_csv(\"./tunis.csv\")\n",
    "\n",
    "full_data = pd.concat([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, \n",
    "                       x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, \n",
    "                      x23, x24])\n",
    "\n",
    "full_data = full_data.drop([\"Unnamed: 0\"], axis=1)    # Remove the index column\n",
    "full_data.to_csv(\"./Unclean_data-tayara.tn.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
